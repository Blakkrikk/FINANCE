{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the file tfdl_env.yml and move it to folder of your choice\n",
    "#Open your terminal cd to the folder in which the file is saved and run \"source activate tfdeeplearning\" (MacOS) or\n",
    "#\"activate tfdeeplearning\" (Windows)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xpatricklorenzx/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from option_prediction import OUTPUT_FOLDER\n",
    "from Option_Accuracy_Analysis import OUTPUT_FOLDER_CPSP\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from TF_Setup import tf_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_TF = \"Tensorflow_DataFrame_csv\"\n",
    "try:\n",
    "    os.mkdir(OUTPUT_FOLDER_TF)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: Tensorflow_DataFrame_csv/2020_09_19/Tensorflow_DataFrame_csv_2020_09_19.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickers</th>\n",
       "      <th>Days_to_Exp</th>\n",
       "      <th>Price @ DtE</th>\n",
       "      <th>CPSP</th>\n",
       "      <th>Actual Price @ Expiry</th>\n",
       "      <th>Expected %Change</th>\n",
       "      <th>Actual %Change</th>\n",
       "      <th>Expected - Actual</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>Beta</th>\n",
       "      <th>1W %Change</th>\n",
       "      <th>50 Day MA</th>\n",
       "      <th>MA to TP %</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>30day Vol</th>\n",
       "      <th>95% VaR</th>\n",
       "      <th>predicted Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>0</td>\n",
       "      <td>12.940000</td>\n",
       "      <td>14.093685</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>8.915656</td>\n",
       "      <td>0.077282</td>\n",
       "      <td>8.838375</td>\n",
       "      <td>6.596036096000001</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>-2.116400</td>\n",
       "      <td>12.490200</td>\n",
       "      <td>-3.550578</td>\n",
       "      <td>-8.004599</td>\n",
       "      <td>4.232225</td>\n",
       "      <td>-13.98</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>1</td>\n",
       "      <td>13.005000</td>\n",
       "      <td>14.067043</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>8.166418</td>\n",
       "      <td>-0.422917</td>\n",
       "      <td>8.589335</td>\n",
       "      <td>6.613835776</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>-0.725193</td>\n",
       "      <td>12.487300</td>\n",
       "      <td>-3.980777</td>\n",
       "      <td>-7.957495</td>\n",
       "      <td>4.239918</td>\n",
       "      <td>-13.98</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>14.173824</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>8.611678</td>\n",
       "      <td>-0.766286</td>\n",
       "      <td>9.377965</td>\n",
       "      <td>6.636721152000001</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.488600</td>\n",
       "      <td>-4.301917</td>\n",
       "      <td>-7.916577</td>\n",
       "      <td>4.312529</td>\n",
       "      <td>-14.01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>3</td>\n",
       "      <td>13.630000</td>\n",
       "      <td>13.857185</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>1.666800</td>\n",
       "      <td>-4.988997</td>\n",
       "      <td>6.655797</td>\n",
       "      <td>6.9316864</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>0.294334</td>\n",
       "      <td>12.494000</td>\n",
       "      <td>-8.334557</td>\n",
       "      <td>-7.821663</td>\n",
       "      <td>4.408780</td>\n",
       "      <td>-13.96</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>4</td>\n",
       "      <td>13.610000</td>\n",
       "      <td>13.889963</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>2.057040</td>\n",
       "      <td>-4.849374</td>\n",
       "      <td>6.906415</td>\n",
       "      <td>6.921515008</td>\n",
       "      <td>1.75418</td>\n",
       "      <td>2.484939</td>\n",
       "      <td>12.469000</td>\n",
       "      <td>-8.383539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.403063</td>\n",
       "      <td>-13.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>ZM</td>\n",
       "      <td>7</td>\n",
       "      <td>382.010010</td>\n",
       "      <td>343.660636</td>\n",
       "      <td>438.730011</td>\n",
       "      <td>-10.038840</td>\n",
       "      <td>14.847779</td>\n",
       "      <td>-24.886619</td>\n",
       "      <td>108.884885504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.575975</td>\n",
       "      <td>285.734199</td>\n",
       "      <td>-25.395771</td>\n",
       "      <td>83.038430</td>\n",
       "      <td>5.828215</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>ZM</td>\n",
       "      <td>8</td>\n",
       "      <td>384.480011</td>\n",
       "      <td>338.960428</td>\n",
       "      <td>438.730011</td>\n",
       "      <td>-11.839259</td>\n",
       "      <td>14.109966</td>\n",
       "      <td>-25.949225</td>\n",
       "      <td>109.3541888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.995541</td>\n",
       "      <td>283.256799</td>\n",
       "      <td>-26.327302</td>\n",
       "      <td>86.821726</td>\n",
       "      <td>5.823968</td>\n",
       "      <td>-9.79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>ZM</td>\n",
       "      <td>9</td>\n",
       "      <td>389.649994</td>\n",
       "      <td>326.577595</td>\n",
       "      <td>438.730011</td>\n",
       "      <td>-16.186937</td>\n",
       "      <td>12.595924</td>\n",
       "      <td>-28.782861</td>\n",
       "      <td>110.824636416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.855425</td>\n",
       "      <td>280.637999</td>\n",
       "      <td>-27.976902</td>\n",
       "      <td>88.062233</td>\n",
       "      <td>5.695144</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>ZM</td>\n",
       "      <td>10</td>\n",
       "      <td>350.880005</td>\n",
       "      <td>336.712712</td>\n",
       "      <td>438.730011</td>\n",
       "      <td>-4.037646</td>\n",
       "      <td>25.037051</td>\n",
       "      <td>-29.074697</td>\n",
       "      <td>99.79763916799999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.245303</td>\n",
       "      <td>277.816199</td>\n",
       "      <td>-20.823018</td>\n",
       "      <td>77.926524</td>\n",
       "      <td>5.636624</td>\n",
       "      <td>-9.74</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>ZM</td>\n",
       "      <td>11</td>\n",
       "      <td>369.890015</td>\n",
       "      <td>328.732340</td>\n",
       "      <td>438.730011</td>\n",
       "      <td>-11.127003</td>\n",
       "      <td>18.610937</td>\n",
       "      <td>-29.737940</td>\n",
       "      <td>105.204482048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.522609</td>\n",
       "      <td>275.934598</td>\n",
       "      <td>-25.400906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.613446</td>\n",
       "      <td>-9.69</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tickers  Days_to_Exp  Price @ DtE        CPSP  Actual Price @ Expiry  \\\n",
       "0       AAL            0    12.940000   14.093685              12.950000   \n",
       "1       AAL            1    13.005000   14.067043              12.950000   \n",
       "2       AAL            2    13.050000   14.173824              12.950000   \n",
       "3       AAL            3    13.630000   13.857185              12.950000   \n",
       "4       AAL            4    13.610000   13.889963              12.950000   \n",
       "..      ...          ...          ...         ...                    ...   \n",
       "595      ZM            7   382.010010  343.660636             438.730011   \n",
       "596      ZM            8   384.480011  338.960428             438.730011   \n",
       "597      ZM            9   389.649994  326.577595             438.730011   \n",
       "598      ZM           10   350.880005  336.712712             438.730011   \n",
       "599      ZM           11   369.890015  328.732340             438.730011   \n",
       "\n",
       "     Expected %Change  Actual %Change  Expected - Actual          MarketCap  \\\n",
       "0            8.915656        0.077282           8.838375  6.596036096000001   \n",
       "1            8.166418       -0.422917           8.589335        6.613835776   \n",
       "2            8.611678       -0.766286           9.377965  6.636721152000001   \n",
       "3            1.666800       -4.988997           6.655797          6.9316864   \n",
       "4            2.057040       -4.849374           6.906415        6.921515008   \n",
       "..                ...             ...                ...                ...   \n",
       "595        -10.038840       14.847779         -24.886619      108.884885504   \n",
       "596        -11.839259       14.109966         -25.949225        109.3541888   \n",
       "597        -16.186937       12.595924         -28.782861      110.824636416   \n",
       "598         -4.037646       25.037051         -29.074697  99.79763916799999   \n",
       "599        -11.127003       18.610937         -29.737940      105.204482048   \n",
       "\n",
       "                   Beta  1W %Change   50 Day MA  MA to TP %  Sharpe Ratio  \\\n",
       "0    1.7541799999999999   -2.116400   12.490200   -3.550578     -8.004599   \n",
       "1    1.7541799999999999   -0.725193   12.487300   -3.980777     -7.957495   \n",
       "2    1.7541799999999999    0.000000   12.488600   -4.301917     -7.916577   \n",
       "3    1.7541799999999999    0.294334   12.494000   -8.334557     -7.821663   \n",
       "4               1.75418    2.484939   12.469000   -8.383539           NaN   \n",
       "..                  ...         ...         ...         ...           ...   \n",
       "595                 NaN   -9.575975  285.734199  -25.395771     83.038430   \n",
       "596                 NaN  -15.995541  283.256799  -26.327302     86.821726   \n",
       "597                 NaN   19.855425  280.637999  -27.976902     88.062233   \n",
       "598                 NaN   17.245303  277.816199  -20.823018     77.926524   \n",
       "599                 NaN   25.522609  275.934598  -25.400906           NaN   \n",
       "\n",
       "     30day Vol  95% VaR predicted Direction  \n",
       "0     4.232225   -13.98             Correct  \n",
       "1     4.239918   -13.98               False  \n",
       "2     4.312529   -14.01               False  \n",
       "3     4.408780   -13.96               False  \n",
       "4     4.403063   -13.99               False  \n",
       "..         ...      ...                 ...  \n",
       "595   5.828215    -9.80               False  \n",
       "596   5.823968    -9.79               False  \n",
       "597   5.695144    -9.80               False  \n",
       "598   5.636624    -9.74               False  \n",
       "599   5.613446    -9.69               False  \n",
       "\n",
       "[600 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_setup(OUTPUT_FOLDER_CPSP=OUTPUT_FOLDER_CPSP, output_folder_tf=OUTPUT_FOLDER_TF, export_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_prediction = pd.read_csv(\"Tensorflow_DataFrame_csv/2020_09_19/Tensorflow_DataFrame_csv_2020_09_19.csv\",\\\n",
    "                                     index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in Data and adjust columns to TF requirements (No spaces, spec characters, etc)\n",
    "stock_price_prediction = stock_price_prediction.replace(\"T E\", 0)\n",
    "stock_price_prediction = stock_price_prediction.replace(\"I E\", 0)\n",
    "stock_price_prediction = stock_price_prediction.fillna(0)\n",
    "\n",
    "stock_price_prediction_tidy = stock_price_prediction.rename(columns = \\\n",
    "                                                            {\"Price @ DtE\": \"Price_at_DtE\",\\\n",
    "                                                             \"Actual Price @ Expiry\": \"Actual_Price_at_Expiry\",\\\n",
    "                                                            \"Expected %Change\": \"Expected_Pct_Change\",\\\n",
    "                                                            \"Actual %Change\": \"Actual_Pct_Change\",\\\n",
    "                                                             \"Expected - Actual\": \"Expected_delta_Actual\",\\\n",
    "                                                             \"1W %Change\": \"One_week_pct_change\",\\\n",
    "                                                            \"50 Day MA\": \"Fifty_Day_MA\",\\\n",
    "                                                            \"MA to TP %\":\"MA_to_TP_Pct\",\\\n",
    "                                                            \"30day Vol\":\"Thirty_day_Vol\",\\\n",
    "                                                             \"Sharpe Ratio\":\"Sharpe_Ratio\",\\\n",
    "                                                            \"95% VaR\": \"VaR\",\\\n",
    "                                                            \"predicted Direction\":\"predicted_Direction\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickers</th>\n",
       "      <th>Days_to_Exp</th>\n",
       "      <th>Price_at_DtE</th>\n",
       "      <th>CPSP</th>\n",
       "      <th>Actual_Price_at_Expiry</th>\n",
       "      <th>Expected_Pct_Change</th>\n",
       "      <th>Actual_Pct_Change</th>\n",
       "      <th>Expected_delta_Actual</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>Beta</th>\n",
       "      <th>One_week_pct_change</th>\n",
       "      <th>Fifty_Day_MA</th>\n",
       "      <th>MA_to_TP_Pct</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Thirty_day_Vol</th>\n",
       "      <th>VaR</th>\n",
       "      <th>predicted_Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>0</td>\n",
       "      <td>12.940000</td>\n",
       "      <td>14.093685</td>\n",
       "      <td>12.95</td>\n",
       "      <td>8.915656</td>\n",
       "      <td>0.077282</td>\n",
       "      <td>8.838375</td>\n",
       "      <td>6.596036096000001</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>-2.116400</td>\n",
       "      <td>12.490200</td>\n",
       "      <td>-3.550578</td>\n",
       "      <td>-8.004599</td>\n",
       "      <td>4.232225</td>\n",
       "      <td>-13.98</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>1</td>\n",
       "      <td>13.005000</td>\n",
       "      <td>14.067043</td>\n",
       "      <td>12.95</td>\n",
       "      <td>8.166418</td>\n",
       "      <td>-0.422917</td>\n",
       "      <td>8.589335</td>\n",
       "      <td>6.613835776</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>-0.725193</td>\n",
       "      <td>12.487300</td>\n",
       "      <td>-3.980777</td>\n",
       "      <td>-7.957495</td>\n",
       "      <td>4.239918</td>\n",
       "      <td>-13.98</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>14.173824</td>\n",
       "      <td>12.95</td>\n",
       "      <td>8.611678</td>\n",
       "      <td>-0.766286</td>\n",
       "      <td>9.377965</td>\n",
       "      <td>6.636721152000001</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.488600</td>\n",
       "      <td>-4.301917</td>\n",
       "      <td>-7.916577</td>\n",
       "      <td>4.312529</td>\n",
       "      <td>-14.01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>3</td>\n",
       "      <td>13.630000</td>\n",
       "      <td>13.857185</td>\n",
       "      <td>12.95</td>\n",
       "      <td>1.666800</td>\n",
       "      <td>-4.988997</td>\n",
       "      <td>6.655797</td>\n",
       "      <td>6.9316864</td>\n",
       "      <td>1.7541799999999999</td>\n",
       "      <td>0.294334</td>\n",
       "      <td>12.494000</td>\n",
       "      <td>-8.334557</td>\n",
       "      <td>-7.821663</td>\n",
       "      <td>4.408780</td>\n",
       "      <td>-13.96</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>4</td>\n",
       "      <td>13.610000</td>\n",
       "      <td>13.889963</td>\n",
       "      <td>12.95</td>\n",
       "      <td>2.057040</td>\n",
       "      <td>-4.849374</td>\n",
       "      <td>6.906415</td>\n",
       "      <td>6.921515008</td>\n",
       "      <td>1.75418</td>\n",
       "      <td>2.484939</td>\n",
       "      <td>12.469000</td>\n",
       "      <td>-8.383539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.403063</td>\n",
       "      <td>-13.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ZM</td>\n",
       "      <td>0</td>\n",
       "      <td>382.010010</td>\n",
       "      <td>387.243126</td>\n",
       "      <td>383.00</td>\n",
       "      <td>1.369890</td>\n",
       "      <td>0.259153</td>\n",
       "      <td>1.110737</td>\n",
       "      <td>108.884885504</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.575975</td>\n",
       "      <td>285.734199</td>\n",
       "      <td>-25.395771</td>\n",
       "      <td>83.038430</td>\n",
       "      <td>5.828215</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ZM</td>\n",
       "      <td>1</td>\n",
       "      <td>384.480011</td>\n",
       "      <td>388.809711</td>\n",
       "      <td>383.00</td>\n",
       "      <td>1.126118</td>\n",
       "      <td>-0.384938</td>\n",
       "      <td>1.511057</td>\n",
       "      <td>109.3541888</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.995541</td>\n",
       "      <td>283.256799</td>\n",
       "      <td>-26.327302</td>\n",
       "      <td>86.821726</td>\n",
       "      <td>5.823968</td>\n",
       "      <td>-9.79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ZM</td>\n",
       "      <td>2</td>\n",
       "      <td>389.649994</td>\n",
       "      <td>380.711124</td>\n",
       "      <td>383.00</td>\n",
       "      <td>-2.294077</td>\n",
       "      <td>-1.706658</td>\n",
       "      <td>-0.587418</td>\n",
       "      <td>110.824636416</td>\n",
       "      <td>0</td>\n",
       "      <td>19.855425</td>\n",
       "      <td>280.637999</td>\n",
       "      <td>-27.976902</td>\n",
       "      <td>88.062233</td>\n",
       "      <td>5.695144</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ZM</td>\n",
       "      <td>3</td>\n",
       "      <td>350.880005</td>\n",
       "      <td>371.154644</td>\n",
       "      <td>383.00</td>\n",
       "      <td>5.778226</td>\n",
       "      <td>9.154125</td>\n",
       "      <td>-3.375899</td>\n",
       "      <td>99.79763916799999</td>\n",
       "      <td>0</td>\n",
       "      <td>17.245303</td>\n",
       "      <td>277.816199</td>\n",
       "      <td>-20.823018</td>\n",
       "      <td>77.926524</td>\n",
       "      <td>5.636624</td>\n",
       "      <td>-9.74</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ZM</td>\n",
       "      <td>4</td>\n",
       "      <td>369.890015</td>\n",
       "      <td>371.536225</td>\n",
       "      <td>383.00</td>\n",
       "      <td>0.445054</td>\n",
       "      <td>3.544293</td>\n",
       "      <td>-3.099239</td>\n",
       "      <td>105.204482048</td>\n",
       "      <td>0</td>\n",
       "      <td>25.522609</td>\n",
       "      <td>275.934598</td>\n",
       "      <td>-25.400906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.613446</td>\n",
       "      <td>-9.69</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tickers  Days_to_Exp  Price_at_DtE        CPSP  Actual_Price_at_Expiry  \\\n",
       "0       AAL            0     12.940000   14.093685                   12.95   \n",
       "1       AAL            1     13.005000   14.067043                   12.95   \n",
       "2       AAL            2     13.050000   14.173824                   12.95   \n",
       "3       AAL            3     13.630000   13.857185                   12.95   \n",
       "4       AAL            4     13.610000   13.889963                   12.95   \n",
       "..      ...          ...           ...         ...                     ...   \n",
       "195      ZM            0    382.010010  387.243126                  383.00   \n",
       "196      ZM            1    384.480011  388.809711                  383.00   \n",
       "197      ZM            2    389.649994  380.711124                  383.00   \n",
       "198      ZM            3    350.880005  371.154644                  383.00   \n",
       "199      ZM            4    369.890015  371.536225                  383.00   \n",
       "\n",
       "     Expected_Pct_Change  Actual_Pct_Change  Expected_delta_Actual  \\\n",
       "0               8.915656           0.077282               8.838375   \n",
       "1               8.166418          -0.422917               8.589335   \n",
       "2               8.611678          -0.766286               9.377965   \n",
       "3               1.666800          -4.988997               6.655797   \n",
       "4               2.057040          -4.849374               6.906415   \n",
       "..                   ...                ...                    ...   \n",
       "195             1.369890           0.259153               1.110737   \n",
       "196             1.126118          -0.384938               1.511057   \n",
       "197            -2.294077          -1.706658              -0.587418   \n",
       "198             5.778226           9.154125              -3.375899   \n",
       "199             0.445054           3.544293              -3.099239   \n",
       "\n",
       "             MarketCap                Beta  One_week_pct_change  Fifty_Day_MA  \\\n",
       "0    6.596036096000001  1.7541799999999999            -2.116400     12.490200   \n",
       "1          6.613835776  1.7541799999999999            -0.725193     12.487300   \n",
       "2    6.636721152000001  1.7541799999999999             0.000000     12.488600   \n",
       "3            6.9316864  1.7541799999999999             0.294334     12.494000   \n",
       "4          6.921515008             1.75418             2.484939     12.469000   \n",
       "..                 ...                 ...                  ...           ...   \n",
       "195      108.884885504                   0            -9.575975    285.734199   \n",
       "196        109.3541888                   0           -15.995541    283.256799   \n",
       "197      110.824636416                   0            19.855425    280.637999   \n",
       "198  99.79763916799999                   0            17.245303    277.816199   \n",
       "199      105.204482048                   0            25.522609    275.934598   \n",
       "\n",
       "     MA_to_TP_Pct  Sharpe_Ratio  Thirty_day_Vol    VaR predicted_Direction  \n",
       "0       -3.550578     -8.004599        4.232225 -13.98             Correct  \n",
       "1       -3.980777     -7.957495        4.239918 -13.98               False  \n",
       "2       -4.301917     -7.916577        4.312529 -14.01               False  \n",
       "3       -8.334557     -7.821663        4.408780 -13.96               False  \n",
       "4       -8.383539      0.000000        4.403063 -13.99               False  \n",
       "..            ...           ...             ...    ...                 ...  \n",
       "195    -25.395771     83.038430        5.828215  -9.80             Correct  \n",
       "196    -26.327302     86.821726        5.823968  -9.79               False  \n",
       "197    -27.976902     88.062233        5.695144  -9.80             Correct  \n",
       "198    -20.823018     77.926524        5.636624  -9.74             Correct  \n",
       "199    -25.400906      0.000000        5.613446  -9.69             Correct  \n",
       "\n",
       "[200 rows x 17 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_price_prediction_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate and select data as preferred\n",
    "y_val = stock_price_prediction_tidy[\"Actual_Price_at_Expiry\"]\n",
    "\n",
    "x_data = stock_price_prediction_tidy.drop([\"Tickers\", \"Expected_delta_Actual\",\"Actual_Pct_Change\",\\\n",
    "                                           \"Actual_Price_at_Expiry\",\\\n",
    "                                           \"predicted_Direction\"],\\\n",
    "                                          axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_val, test_size=0.2, random_state=101)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust data to Tensorflow environment\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train), \\\n",
    "                      columns=X_train.columns,\\\n",
    "                      index=X_train.index)\n",
    "\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), \\\n",
    "                      columns=X_test.columns,\\\n",
    "                      index=X_test.index)\n",
    "\n",
    "dte = tf.feature_column.numeric_column('Days_to_Exp')\n",
    "dte_price = tf.feature_column.numeric_column('Price_at_DtE')\n",
    "cpsp = tf.feature_column.numeric_column('CPSP')\n",
    "exp_change = tf.feature_column.numeric_column('Expected_Pct_Change')\n",
    "week_change = tf.feature_column.numeric_column('One_week_pct_change')\n",
    "market_cap = tf.feature_column.numeric_column('MarketCap')\n",
    "beta = tf.feature_column.numeric_column('Beta')\n",
    "day_MA = tf.feature_column.numeric_column('Fifty_Day_MA')\n",
    "MA_to_AP_pct = tf.feature_column.numeric_column('MA_to_TP_Pct')\n",
    "sharpe = tf.feature_column.numeric_column('Sharpe_Ratio')\n",
    "day_Vol = tf.feature_column.numeric_column('Thirty_day_Vol')\n",
    "VaR = tf.feature_column.numeric_column('VaR')\n",
    "\n",
    "feat_cols = [dte, dte_price, cpsp, exp_change, week_change, market_cap, beta, \\\n",
    "             day_MA, MA_to_AP_pct, sharpe, day_Vol, VaR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/r_/l39j9z1j6bx3g1s30j_9rtx40000gn/T/tmpc0s7167a\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_experimental_distribute': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2d384208>, '_task_id': 0, '_is_chief': True, '_model_dir': '/var/folders/r_/l39j9z1j6bx3g1s30j_9rtx40000gn/T/tmpc0s7167a', '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_task_type': 'worker', '_service': None, '_session_creation_timeout_secs': 7200, '_experimental_max_worker_delay_secs': None, '_keep_checkpoint_max': 5, '_train_distribute': None, '_device_fn': None, '_tf_random_seed': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_protocol': None, '_evaluation_master': '', '_eval_distribute': None, '_num_ps_replicas': 0}\n"
     ]
    }
   ],
   "source": [
    "#Write input function and estimator model (variables: layers and hidden units)\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, \n",
    "                                                 y=y_train,\n",
    "                                                batch_size=10,\n",
    "                                                num_epochs=1000,\n",
    "                                                shuffle=True)\n",
    "\n",
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6,6], feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/r_/l39j9z1j6bx3g1s30j_9rtx40000gn/T/tmpc0s7167a/model.ckpt.\n",
      "INFO:tensorflow:loss = 2784860.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 104.654\n",
      "INFO:tensorflow:loss = 1386342.2, step = 101 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.929\n",
      "INFO:tensorflow:loss = 1246666.9, step = 201 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.284\n",
      "INFO:tensorflow:loss = 448894.12, step = 301 (0.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.473\n",
      "INFO:tensorflow:loss = 202638.08, step = 401 (0.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.336\n",
      "INFO:tensorflow:loss = 146244.73, step = 501 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.469\n",
      "INFO:tensorflow:loss = 14378.801, step = 601 (0.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.785\n",
      "INFO:tensorflow:loss = 129010.516, step = 701 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.663\n",
      "INFO:tensorflow:loss = 13000.831, step = 801 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.477\n",
      "INFO:tensorflow:loss = 87934.87, step = 901 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.571\n",
      "INFO:tensorflow:loss = 15821.133, step = 1001 (0.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.261\n",
      "INFO:tensorflow:loss = 10470.95, step = 1101 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.709\n",
      "INFO:tensorflow:loss = 99783.39, step = 1201 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.897\n",
      "INFO:tensorflow:loss = 38162.734, step = 1301 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.11\n",
      "INFO:tensorflow:loss = 28601.102, step = 1401 (0.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.387\n",
      "INFO:tensorflow:loss = 42985.797, step = 1501 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.953\n",
      "INFO:tensorflow:loss = 31515.537, step = 1601 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.222\n",
      "INFO:tensorflow:loss = 8319.549, step = 1701 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.219\n",
      "INFO:tensorflow:loss = 16246.587, step = 1801 (0.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.926\n",
      "INFO:tensorflow:loss = 8641.464, step = 1901 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.89\n",
      "INFO:tensorflow:loss = 12373.911, step = 2001 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.161\n",
      "INFO:tensorflow:loss = 10827.578, step = 2101 (0.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.334\n",
      "INFO:tensorflow:loss = 4393.046, step = 2201 (0.742 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2240 vs previous value: 2240. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 115.883\n",
      "INFO:tensorflow:loss = 18063.898, step = 2301 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.808\n",
      "INFO:tensorflow:loss = 15334.264, step = 2401 (0.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.061\n",
      "INFO:tensorflow:loss = 8045.4326, step = 2501 (0.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.996\n",
      "INFO:tensorflow:loss = 6392.176, step = 2601 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.605\n",
      "INFO:tensorflow:loss = 5126.776, step = 2701 (0.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.552\n",
      "INFO:tensorflow:loss = 4884.177, step = 2801 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.923\n",
      "INFO:tensorflow:loss = 1924.384, step = 2901 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.634\n",
      "INFO:tensorflow:loss = 19051.996, step = 3001 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.143\n",
      "INFO:tensorflow:loss = 5420.2812, step = 3101 (0.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.255\n",
      "INFO:tensorflow:loss = 5196.261, step = 3201 (0.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.466\n",
      "INFO:tensorflow:loss = 30870.865, step = 3301 (0.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.769\n",
      "INFO:tensorflow:loss = 4976.9863, step = 3401 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.161\n",
      "INFO:tensorflow:loss = 3492.568, step = 3501 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.242\n",
      "INFO:tensorflow:loss = 3421.9268, step = 3601 (0.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.728\n",
      "INFO:tensorflow:loss = 4310.1416, step = 3701 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.868\n",
      "INFO:tensorflow:loss = 3194.2095, step = 3801 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.367\n",
      "INFO:tensorflow:loss = 1288.5718, step = 3901 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.361\n",
      "INFO:tensorflow:loss = 1688.7933, step = 4001 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.084\n",
      "INFO:tensorflow:loss = 3730.922, step = 4101 (0.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.96\n",
      "INFO:tensorflow:loss = 1618.9482, step = 4201 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.413\n",
      "INFO:tensorflow:loss = 2446.4287, step = 4301 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.898\n",
      "INFO:tensorflow:loss = 10375.924, step = 4401 (0.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.831\n",
      "INFO:tensorflow:loss = 3916.069, step = 4501 (0.741 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 151.75\n",
      "INFO:tensorflow:loss = 2947.587, step = 4601 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.751\n",
      "INFO:tensorflow:loss = 3068.2812, step = 4701 (0.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.791\n",
      "INFO:tensorflow:loss = 5537.7397, step = 4801 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.167\n",
      "INFO:tensorflow:loss = 2364.5552, step = 4901 (0.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.496\n",
      "INFO:tensorflow:loss = 2962.6216, step = 5001 (0.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.179\n",
      "INFO:tensorflow:loss = 1301.623, step = 5101 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.1171\n",
      "INFO:tensorflow:loss = 4754.2354, step = 5201 (1.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.265\n",
      "INFO:tensorflow:loss = 3965.5513, step = 5301 (0.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.298\n",
      "INFO:tensorflow:loss = 3749.1113, step = 5401 (0.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.099\n",
      "INFO:tensorflow:loss = 2471.406, step = 5501 (0.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.594\n",
      "INFO:tensorflow:loss = 4692.7905, step = 5601 (0.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.441\n",
      "INFO:tensorflow:loss = 1417.8296, step = 5701 (0.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7155\n",
      "INFO:tensorflow:loss = 561.70404, step = 5801 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.647\n",
      "INFO:tensorflow:loss = 4163.1274, step = 5901 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.654\n",
      "INFO:tensorflow:loss = 2254.3633, step = 6001 (0.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.861\n",
      "INFO:tensorflow:loss = 2482.2324, step = 6101 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.582\n",
      "INFO:tensorflow:loss = 873.4234, step = 6201 (0.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.91\n",
      "INFO:tensorflow:loss = 1425.0681, step = 6301 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.999\n",
      "INFO:tensorflow:loss = 3318.975, step = 6401 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.621\n",
      "INFO:tensorflow:loss = 1775.4724, step = 6501 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.821\n",
      "INFO:tensorflow:loss = 677.6628, step = 6601 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.628\n",
      "INFO:tensorflow:loss = 848.7573, step = 6701 (0.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.264\n",
      "INFO:tensorflow:loss = 1345.3444, step = 6801 (0.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.315\n",
      "INFO:tensorflow:loss = 1477.7949, step = 6901 (0.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.943\n",
      "INFO:tensorflow:loss = 1832.164, step = 7001 (0.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.923\n",
      "INFO:tensorflow:loss = 984.49817, step = 7101 (0.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.826\n",
      "INFO:tensorflow:loss = 926.8464, step = 7201 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.722\n",
      "INFO:tensorflow:loss = 438.85428, step = 7301 (0.721 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7302 vs previous value: 7302. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 157.37\n",
      "INFO:tensorflow:loss = 1475.5029, step = 7401 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.679\n",
      "INFO:tensorflow:loss = 668.89264, step = 7501 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.808\n",
      "INFO:tensorflow:loss = 3059.859, step = 7601 (0.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.021\n",
      "INFO:tensorflow:loss = 1801.9812, step = 7701 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.167\n",
      "INFO:tensorflow:loss = 771.66016, step = 7801 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.721\n",
      "INFO:tensorflow:loss = 4948.8936, step = 7901 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.987\n",
      "INFO:tensorflow:loss = 3888.0884, step = 8001 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.957\n",
      "INFO:tensorflow:loss = 2337.6138, step = 8101 (0.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.78\n",
      "INFO:tensorflow:loss = 895.5121, step = 8201 (0.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.816\n",
      "INFO:tensorflow:loss = 1732.4529, step = 8301 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.336\n",
      "INFO:tensorflow:loss = 3132.0244, step = 8401 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.129\n",
      "INFO:tensorflow:loss = 473.4742, step = 8501 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.209\n",
      "INFO:tensorflow:loss = 1070.5718, step = 8601 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.417\n",
      "INFO:tensorflow:loss = 450.15186, step = 8701 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.121\n",
      "INFO:tensorflow:loss = 1797.327, step = 8801 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.29\n",
      "INFO:tensorflow:loss = 129.95706, step = 8901 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.202\n",
      "INFO:tensorflow:loss = 1694.9735, step = 9001 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.649\n",
      "INFO:tensorflow:loss = 323.55283, step = 9101 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.556\n",
      "INFO:tensorflow:loss = 310.5457, step = 9201 (0.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0738\n",
      "INFO:tensorflow:loss = 723.4078, step = 9301 (1.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.156\n",
      "INFO:tensorflow:loss = 1701.5198, step = 9401 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.513\n",
      "INFO:tensorflow:loss = 1452.3092, step = 9501 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.44\n",
      "INFO:tensorflow:loss = 710.5648, step = 9601 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.552\n",
      "INFO:tensorflow:loss = 1004.15466, step = 9701 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.549\n",
      "INFO:tensorflow:loss = 869.9857, step = 9801 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.707\n",
      "INFO:tensorflow:loss = 1537.1067, step = 9901 (0.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.792\n",
      "INFO:tensorflow:loss = 4011.6113, step = 10001 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.792\n",
      "INFO:tensorflow:loss = 864.68054, step = 10101 (0.831 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10187 vs previous value: 10187. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 134.215\n",
      "INFO:tensorflow:loss = 459.04144, step = 10201 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.156\n",
      "INFO:tensorflow:loss = 787.385, step = 10301 (0.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.214\n",
      "INFO:tensorflow:loss = 353.1894, step = 10401 (0.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.293\n",
      "INFO:tensorflow:loss = 353.2934, step = 10501 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.387\n",
      "INFO:tensorflow:loss = 525.03156, step = 10601 (0.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.487\n",
      "INFO:tensorflow:loss = 374.33405, step = 10701 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.687\n",
      "INFO:tensorflow:loss = 1553.6425, step = 10801 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.364\n",
      "INFO:tensorflow:loss = 1378.0001, step = 10901 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.034\n",
      "INFO:tensorflow:loss = 1030.2439, step = 11001 (0.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.934\n",
      "INFO:tensorflow:loss = 229.53842, step = 11101 (0.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.395\n",
      "INFO:tensorflow:loss = 1216.0216, step = 11201 (0.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.935\n",
      "INFO:tensorflow:loss = 2611.063, step = 11301 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.975\n",
      "INFO:tensorflow:loss = 1258.3196, step = 11401 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.663\n",
      "INFO:tensorflow:loss = 1266.9523, step = 11501 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.014\n",
      "INFO:tensorflow:loss = 2390.871, step = 11601 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.277\n",
      "INFO:tensorflow:loss = 1447.9634, step = 11701 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.507\n",
      "INFO:tensorflow:loss = 261.4966, step = 11801 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.615\n",
      "INFO:tensorflow:loss = 2308.98, step = 11901 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.773\n",
      "INFO:tensorflow:loss = 3143.8438, step = 12001 (0.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.484\n",
      "INFO:tensorflow:loss = 1008.0601, step = 12101 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.053\n",
      "INFO:tensorflow:loss = 1418.6979, step = 12201 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1249.0426, step = 12301 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.193\n",
      "INFO:tensorflow:loss = 815.6037, step = 12401 (0.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.551\n",
      "INFO:tensorflow:loss = 3204.8813, step = 12501 (0.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.467\n",
      "INFO:tensorflow:loss = 1249.7087, step = 12601 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.63\n",
      "INFO:tensorflow:loss = 1139.9163, step = 12701 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.828\n",
      "INFO:tensorflow:loss = 581.56177, step = 12801 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.94\n",
      "INFO:tensorflow:loss = 198.94139, step = 12901 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.156\n",
      "INFO:tensorflow:loss = 886.51154, step = 13001 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.062\n",
      "INFO:tensorflow:loss = 333.60614, step = 13101 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.364\n",
      "INFO:tensorflow:loss = 801.8882, step = 13201 (0.698 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 13211 vs previous value: 13211. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 124.767\n",
      "INFO:tensorflow:loss = 337.0158, step = 13301 (0.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.221\n",
      "INFO:tensorflow:loss = 613.0064, step = 13401 (0.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.448\n",
      "INFO:tensorflow:loss = 240.07443, step = 13501 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.683\n",
      "INFO:tensorflow:loss = 217.80678, step = 13601 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.965\n",
      "INFO:tensorflow:loss = 993.0541, step = 13701 (1.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.776\n",
      "INFO:tensorflow:loss = 1112.2174, step = 13801 (0.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.633\n",
      "INFO:tensorflow:loss = 717.53687, step = 13901 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.32\n",
      "INFO:tensorflow:loss = 458.44998, step = 14001 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.937\n",
      "INFO:tensorflow:loss = 2260.3806, step = 14101 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.176\n",
      "INFO:tensorflow:loss = 762.64746, step = 14201 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.295\n",
      "INFO:tensorflow:loss = 1572.9061, step = 14301 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.136\n",
      "INFO:tensorflow:loss = 487.5649, step = 14401 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.722\n",
      "INFO:tensorflow:loss = 3845.67, step = 14501 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.146\n",
      "INFO:tensorflow:loss = 258.80756, step = 14601 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.968\n",
      "INFO:tensorflow:loss = 940.7978, step = 14701 (0.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.3\n",
      "INFO:tensorflow:loss = 2072.0535, step = 14801 (0.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.245\n",
      "INFO:tensorflow:loss = 593.4431, step = 14901 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.36\n",
      "INFO:tensorflow:loss = 570.21173, step = 15001 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.439\n",
      "INFO:tensorflow:loss = 300.81335, step = 15101 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.137\n",
      "INFO:tensorflow:loss = 524.72833, step = 15201 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.518\n",
      "INFO:tensorflow:loss = 291.39667, step = 15301 (0.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.176\n",
      "INFO:tensorflow:loss = 2395.9067, step = 15401 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.835\n",
      "INFO:tensorflow:loss = 381.43582, step = 15501 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.241\n",
      "INFO:tensorflow:loss = 322.27493, step = 15601 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.975\n",
      "INFO:tensorflow:loss = 1430.1371, step = 15701 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.222\n",
      "INFO:tensorflow:loss = 1091.7856, step = 15801 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.763\n",
      "INFO:tensorflow:loss = 2692.1514, step = 15901 (0.640 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into /var/folders/r_/l39j9z1j6bx3g1s30j_9rtx40000gn/T/tmpc0s7167a/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 483.6554.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x1a2d384668>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.train(input_fn=input_func, steps = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/r_/l39j9z1j6bx3g1s30j_9rtx40000gn/T/tmpc0s7167a/model.ckpt-16000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "#Run prediction of the tensorflow algorithm to check how accurate the predictions were\n",
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test,\\\n",
    "                                                        batch_size=10,\\\n",
    "                                                        num_epochs=1,\\\n",
    "                                                        shuffle = False)\n",
    "\n",
    "pred_gen = model.predict(predict_input_func)\n",
    "\n",
    "predictions = list(pred_gen)\n",
    "\n",
    "#Final_preds is a list of predictions tensorflow did with the X_train as input\n",
    "final_preds = []\n",
    "\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "#y_test\n",
    "#stock_price_prediction_tidy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Root Mean Squared Error:  6.922602365712964\n",
      "The RMSE in relation to mean value:  97.422879745935 %\n",
      "The R-Squared Score:  0.9971127319958633\n"
     ]
    }
   ],
   "source": [
    "#Check for accuracy of the predictive model with the Y-Test data using RMSE and R^2\n",
    "rmse = mean_squared_error(y_test, final_preds)**0.5\n",
    "\n",
    "tf_accuracy = 100-(rmse / stock_price_prediction_tidy[\"Actual_Price_at_Expiry\"].mean())*100\n",
    "tf_r2 = r2_score(y_test, final_preds)\n",
    "print(\"The Root Mean Squared Error: \", rmse)\n",
    "print(\"The RMSE in relation to mean value: \", tf_accuracy,\"%\")\n",
    "print(\"The R-Squared Score: \",tf_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow correctly predicted 26 out of 40  hence a  65.0 % Accuracy\n",
      "14 incorrectly predicted out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickers</th>\n",
       "      <th>Days_to_Exp</th>\n",
       "      <th>Price_at_DtE</th>\n",
       "      <th>Actual Prices</th>\n",
       "      <th>Tensorflow Prices</th>\n",
       "      <th>Hindsight Prediction</th>\n",
       "      <th>Tensorflow Prediction</th>\n",
       "      <th>predicted Direction Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>13.847249</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2</td>\n",
       "      <td>81.910004</td>\n",
       "      <td>76.339996</td>\n",
       "      <td>77.997513</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ATVI</td>\n",
       "      <td>2</td>\n",
       "      <td>79.589996</td>\n",
       "      <td>77.970001</td>\n",
       "      <td>80.838867</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BA</td>\n",
       "      <td>0</td>\n",
       "      <td>160.029999</td>\n",
       "      <td>160.229996</td>\n",
       "      <td>153.347549</td>\n",
       "      <td>buy</td>\n",
       "      <td>sell</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BABA</td>\n",
       "      <td>1</td>\n",
       "      <td>267.549988</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>269.304474</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BABA</td>\n",
       "      <td>2</td>\n",
       "      <td>273.149994</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>272.660217</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BABA</td>\n",
       "      <td>4</td>\n",
       "      <td>281.390015</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>267.574158</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BYND</td>\n",
       "      <td>2</td>\n",
       "      <td>138.169998</td>\n",
       "      <td>134.880005</td>\n",
       "      <td>134.931046</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BYND</td>\n",
       "      <td>4</td>\n",
       "      <td>125.820000</td>\n",
       "      <td>134.880005</td>\n",
       "      <td>114.482826</td>\n",
       "      <td>buy</td>\n",
       "      <td>sell</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>50.950001</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>48.753902</td>\n",
       "      <td>buy</td>\n",
       "      <td>sell</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>49.134495</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>31.787001</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>32.642075</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DAL</td>\n",
       "      <td>4</td>\n",
       "      <td>31.770000</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>34.096375</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DIS</td>\n",
       "      <td>0</td>\n",
       "      <td>131.679993</td>\n",
       "      <td>131.750000</td>\n",
       "      <td>132.450745</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>6.910000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.106857</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>FB</td>\n",
       "      <td>0</td>\n",
       "      <td>266.649994</td>\n",
       "      <td>266.609985</td>\n",
       "      <td>269.916992</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>FB</td>\n",
       "      <td>1</td>\n",
       "      <td>268.089996</td>\n",
       "      <td>266.609985</td>\n",
       "      <td>269.389465</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>GE</td>\n",
       "      <td>4</td>\n",
       "      <td>6.420000</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>10.884919</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>INTC</td>\n",
       "      <td>4</td>\n",
       "      <td>50.080002</td>\n",
       "      <td>49.279999</td>\n",
       "      <td>50.792957</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>JPM</td>\n",
       "      <td>0</td>\n",
       "      <td>101.110001</td>\n",
       "      <td>101.070000</td>\n",
       "      <td>103.078369</td>\n",
       "      <td>sell</td>\n",
       "      <td>buy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>4</td>\n",
       "      <td>214.250000</td>\n",
       "      <td>204.029999</td>\n",
       "      <td>204.577820</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2</td>\n",
       "      <td>500.190002</td>\n",
       "      <td>482.029999</td>\n",
       "      <td>496.915375</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>4</td>\n",
       "      <td>504.899994</td>\n",
       "      <td>486.579987</td>\n",
       "      <td>476.789093</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>270.190002</td>\n",
       "      <td>270.450012</td>\n",
       "      <td>277.668213</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>4</td>\n",
       "      <td>283.579987</td>\n",
       "      <td>270.450012</td>\n",
       "      <td>272.266876</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>SBUX</td>\n",
       "      <td>3</td>\n",
       "      <td>85.410004</td>\n",
       "      <td>85.269997</td>\n",
       "      <td>80.954926</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>1</td>\n",
       "      <td>23.309999</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>33.249706</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>2</td>\n",
       "      <td>23.650000</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>33.594219</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>SNE</td>\n",
       "      <td>0</td>\n",
       "      <td>76.989998</td>\n",
       "      <td>77.019997</td>\n",
       "      <td>81.328094</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>SNE</td>\n",
       "      <td>3</td>\n",
       "      <td>76.010002</td>\n",
       "      <td>77.019997</td>\n",
       "      <td>76.579391</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>SNE</td>\n",
       "      <td>4</td>\n",
       "      <td>77.660004</td>\n",
       "      <td>77.019997</td>\n",
       "      <td>74.536560</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>SPY</td>\n",
       "      <td>3</td>\n",
       "      <td>333.209991</td>\n",
       "      <td>334.059998</td>\n",
       "      <td>321.528931</td>\n",
       "      <td>buy</td>\n",
       "      <td>sell</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SQ</td>\n",
       "      <td>3</td>\n",
       "      <td>139.110001</td>\n",
       "      <td>137.449997</td>\n",
       "      <td>129.757812</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>UAL</td>\n",
       "      <td>0</td>\n",
       "      <td>36.075001</td>\n",
       "      <td>36.070000</td>\n",
       "      <td>31.418974</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>UAL</td>\n",
       "      <td>2</td>\n",
       "      <td>36.029999</td>\n",
       "      <td>36.070000</td>\n",
       "      <td>32.037350</td>\n",
       "      <td>buy</td>\n",
       "      <td>sell</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>UAL</td>\n",
       "      <td>4</td>\n",
       "      <td>38.209999</td>\n",
       "      <td>36.070000</td>\n",
       "      <td>38.077068</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>UBER</td>\n",
       "      <td>0</td>\n",
       "      <td>36.915001</td>\n",
       "      <td>36.980000</td>\n",
       "      <td>46.848026</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>UBER</td>\n",
       "      <td>4</td>\n",
       "      <td>33.240002</td>\n",
       "      <td>36.980000</td>\n",
       "      <td>34.362907</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>200.429993</td>\n",
       "      <td>200.679993</td>\n",
       "      <td>202.582581</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ZM</td>\n",
       "      <td>1</td>\n",
       "      <td>384.480011</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>364.282745</td>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tickers  Days_to_Exp  Price_at_DtE  Actual Prices  Tensorflow Prices  \\\n",
       "2       AAL            2     13.050000      12.950000          13.847249   \n",
       "12      AMD            2     81.910004      76.339996          77.997513   \n",
       "22     ATVI            2     79.589996      77.970001          80.838867   \n",
       "25       BA            0    160.029999     160.229996         153.347549   \n",
       "31     BABA            1    267.549988     271.609985         269.304474   \n",
       "32     BABA            2    273.149994     271.609985         272.660217   \n",
       "34     BABA            4    281.390015     271.609985         267.574158   \n",
       "37     BYND            2    138.169998     134.880005         134.931046   \n",
       "39     BYND            4    125.820000     134.880005         114.482826   \n",
       "41        C            1     50.950001      51.000000          48.753902   \n",
       "42        C            2     51.400002      51.000000          49.134495   \n",
       "50      DAL            0     31.787001      31.700001          32.642075   \n",
       "54      DAL            4     31.770000      31.700001          34.096375   \n",
       "55      DIS            0    131.679993     131.750000         132.450745   \n",
       "61        F            1      6.910000       7.000000          14.106857   \n",
       "65       FB            0    266.649994     266.609985         269.916992   \n",
       "66       FB            1    268.089996     266.609985         269.389465   \n",
       "74       GE            4      6.420000       5.950000          10.884919   \n",
       "89     INTC            4     50.080002      49.279999          50.792957   \n",
       "90      JPM            0    101.110001     101.070000         103.078369   \n",
       "109    MSFT            4    214.250000     204.029999         204.577820   \n",
       "112    NFLX            2    500.190002     482.029999         496.915375   \n",
       "119    NVDA            4    504.899994     486.579987         476.789093   \n",
       "125     QQQ            0    270.190002     270.450012         277.668213   \n",
       "129     QQQ            4    283.579987     270.450012         272.266876   \n",
       "133    SBUX            3     85.410004      85.269997          80.954926   \n",
       "141    SNAP            1     23.309999      24.190001          33.249706   \n",
       "142    SNAP            2     23.650000      24.190001          33.594219   \n",
       "145     SNE            0     76.989998      77.019997          81.328094   \n",
       "148     SNE            3     76.010002      77.019997          76.579391   \n",
       "149     SNE            4     77.660004      77.019997          74.536560   \n",
       "153     SPY            3    333.209991     334.059998         321.528931   \n",
       "158      SQ            3    139.110001     137.449997         129.757812   \n",
       "170     UAL            0     36.075001      36.070000          31.418974   \n",
       "172     UAL            2     36.029999      36.070000          32.037350   \n",
       "174     UAL            4     38.209999      36.070000          38.077068   \n",
       "175    UBER            0     36.915001      36.980000          46.848026   \n",
       "179    UBER            4     33.240002      36.980000          34.362907   \n",
       "180       V            0    200.429993     200.679993         202.582581   \n",
       "196      ZM            1    384.480011     383.000000         364.282745   \n",
       "\n",
       "    Hindsight Prediction Tensorflow Prediction predicted Direction Accuracy  \n",
       "2                   sell                   buy                        False  \n",
       "12                  sell                  sell                      Correct  \n",
       "22                  sell                   buy                        False  \n",
       "25                   buy                  sell                        False  \n",
       "31                   buy                   buy                      Correct  \n",
       "32                  sell                  sell                      Correct  \n",
       "34                  sell                  sell                      Correct  \n",
       "37                  sell                  sell                      Correct  \n",
       "39                   buy                  sell                        False  \n",
       "41                   buy                  sell                        False  \n",
       "42                  sell                  sell                      Correct  \n",
       "50                  sell                   buy                        False  \n",
       "54                  sell                   buy                        False  \n",
       "55                   buy                   buy                      Correct  \n",
       "61                   buy                   buy                      Correct  \n",
       "65                  sell                   buy                        False  \n",
       "66                  sell                   buy                        False  \n",
       "74                  sell                   buy                        False  \n",
       "89                  sell                   buy                        False  \n",
       "90                  sell                   buy                        False  \n",
       "109                 sell                  sell                      Correct  \n",
       "112                 sell                  sell                      Correct  \n",
       "119                 sell                  sell                      Correct  \n",
       "125                  buy                   buy                      Correct  \n",
       "129                 sell                  sell                      Correct  \n",
       "133                 sell                  sell                      Correct  \n",
       "141                  buy                   buy                      Correct  \n",
       "142                  buy                   buy                      Correct  \n",
       "145                  buy                   buy                      Correct  \n",
       "148                  buy                   buy                      Correct  \n",
       "149                 sell                  sell                      Correct  \n",
       "153                  buy                  sell                        False  \n",
       "158                 sell                  sell                      Correct  \n",
       "170                 sell                  sell                      Correct  \n",
       "172                  buy                  sell                        False  \n",
       "174                 sell                  sell                      Correct  \n",
       "175                  buy                   buy                      Correct  \n",
       "179                  buy                   buy                      Correct  \n",
       "180                  buy                   buy                      Correct  \n",
       "196                 sell                  sell                      Correct  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how often the direction of the prediction was accurate (a predicted buy was actually a buy in hindsight)\n",
    "index_list = np.arange(0,np.shape(final_preds)[0],1)\n",
    "\n",
    "final_preds_list = []\n",
    "\n",
    "for y in index_list:\n",
    "    final_preds_index = final_preds[y][0]\n",
    "    final_preds_list.append(final_preds_index)\n",
    "\n",
    "Tensorflow_Acc = pd.DataFrame({\"Actual Prices\":y_test, \"Tensorflow Prices\": final_preds_list})\n",
    "tf_df_merged = pd.merge(stock_price_prediction_tidy, Tensorflow_Acc, right_index=True, left_index=True, how='inner')\n",
    "tf_price_predictions = tf_df_merged[[\"Tickers\",\"Days_to_Exp\",\"Price_at_DtE\",\"Actual Prices\",\"Tensorflow Prices\"]]\n",
    "\n",
    "ePredictions = []\n",
    "aPredictions = []\n",
    "\n",
    "for x,y in zip(tf_price_predictions[\"Price_at_DtE\"],tf_price_predictions[\"Actual Prices\"]):\n",
    "    if x < y:\n",
    "        ePredictions.append(\"buy\")\n",
    "    else:\n",
    "        ePredictions.append(\"sell\")\n",
    "\n",
    "for x,y in zip(tf_price_predictions[\"Price_at_DtE\"],tf_price_predictions[\"Tensorflow Prices\"]):\n",
    "    if x < y:\n",
    "        aPredictions.append(\"buy\")\n",
    "    else:\n",
    "        aPredictions.append(\"sell\")\n",
    "\n",
    "Prediction = []\n",
    "for x,y in zip(ePredictions, aPredictions):\n",
    "    if x == y:\n",
    "        Prediction.append(\"Correct\")\n",
    "    else:\n",
    "        Prediction.append(\"False\")\n",
    "\n",
    "shape = np.shape(tf_price_predictions)[0]\n",
    "da = Prediction.count(\"Correct\")/shape*100\n",
    "\n",
    "print(\"Tensorflow correctly predicted\",Prediction.count(\"Correct\"), \"out of\",shape,\" hence a \",da,\"% Accuracy\" )\n",
    "print(Prediction.count(\"False\"), \"incorrectly predicted out of\", shape)\n",
    "tf_price_predictions[\"Hindsight Prediction\"] = ePredictions\n",
    "tf_price_predictions[\"Tensorflow Prediction\"] = aPredictions\n",
    "tf_price_predictions[\"predicted Direction Accuracy\"] = Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Expected Value for all executed trades is  0.798 % per week\n",
      "This implies a yearly Risk Free Rate of Return of  41.496 % without compounding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/xpatricklorenzx/opt/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Calculate the expected return if all trades would have been executed as predicted by TF\n",
    "tf_price_predictions[\"Actual_gain\"] = ((tf_price_predictions[\"Actual Prices\"] - tf_price_predictions[\"Price_at_DtE\"])\\\n",
    "                                   / tf_price_predictions[\"Price_at_DtE\"])*100\n",
    "\n",
    "tf_price_predictions[\"Expected_gain\"] = ((tf_price_predictions[\"Tensorflow Prices\"] - \\\n",
    "                                          tf_price_predictions[\"Price_at_DtE\"]) / \\\n",
    "                                         tf_price_predictions[\"Price_at_DtE\"])*100\n",
    "\n",
    "Index_label_tf = tf_price_predictions[tf_price_predictions['Tensorflow Prediction']==\"buy\"].index.tolist()\n",
    "Index_label_correct = tf_price_predictions[tf_price_predictions['predicted Direction Accuracy']\\\n",
    "                                           ==\"Correct\"].index.tolist()\n",
    "\n",
    "index_merged_list_correct = []\n",
    "\n",
    "for x in Index_label_tf:\n",
    "    if x in Index_label_correct:\n",
    "        index_merged_list_correct.append(x)\n",
    "\n",
    "Index_label_false = tf_price_predictions[tf_price_predictions['predicted Direction Accuracy']==\"False\"].index.tolist()\n",
    "\n",
    "index_merged_list_false = []\n",
    "\n",
    "for x in Index_label_tf:\n",
    "    if x in Index_label_false:\n",
    "        index_merged_list_false.append(x)\n",
    "\n",
    "gain_total = []\n",
    "\n",
    "for x in index_merged_list_correct:\n",
    "    rowData = tf_price_predictions.loc[x, \"Actual_gain\"]\n",
    "    gain_total.append(rowData)\n",
    "    \n",
    "prediction_mean_gain = np.mean(gain_total)\n",
    "\n",
    "loss_total = []\n",
    "\n",
    "for x in index_merged_list_false:\n",
    "    rowData = tf_price_predictions.loc[x, \"Actual_gain\"]\n",
    "    loss_total.append(rowData)\n",
    "    \n",
    "prediction_mean_loss = np.mean(loss_total)\n",
    "\n",
    "Expected_Value = round((prediction_mean_gain * (da/100)) + (prediction_mean_loss * (1-(da/100))),3)\n",
    "\n",
    "print(\"The Expected Value for all executed trades is \",Expected_Value,\"% per week\")\n",
    "Expected_Value_yearly = Expected_Value * 52\n",
    "print(\"This implies a yearly Risk Free Rate of Return of \", Expected_Value_yearly, \"% without compounding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a300c9128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Expected Gain by TF vs Actual Gain\n",
    "plt.figure(figsize= (16,9))\n",
    "plt.scatter(tf_price_predictions[\"Expected_gain\"], tf_price_predictions[\"Actual_gain\"])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
